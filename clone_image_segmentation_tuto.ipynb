{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clone_image-segmentation_tuto.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8LCQJ8qxB1spQXQQA3frY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanhoLee/colab_studying/blob/main/clone_image_segmentation_tuto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[참고한 코랩](https://www.tensorflow.org/tutorials/images/segmentation)"
      ],
      "metadata": {
        "id": "Y4TQ51FGchaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 튜토리얼은 수정된 [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) 을 이용하여 이미지 세그멘테이션에 집중합니다."
      ],
      "metadata": {
        "id": "w1cfczJIdBLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 분할이란?"
      ],
      "metadata": {
        "id": "Q1Vj9T9tdLeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 네트워크의 과제가 입력 이미지에 레이블이나 클래스를 할당하는 이미지 분류를 보았습니다. 그러나 이미지에서 개체가 있는 위치, 해당 개체의 모양, 어떤 픽셀이 어떤 객체에 속하는지 등을 알고 싶다고 가정해 보세요. 이 경우 이미지를 분할하고 싶을 것입니다. 즉, 이미지의 각 픽셀에 레이블이 부여됩니다. 따라서 영상 분할의 과제는 영상의 픽셀 단위의 마스크를 출력하도록 신경망를 훈련시키는 것입니다.이것은 훨씬 낮은 레벨, 즉 픽셀 레벨에서 이미지를 이해하는 데 도움이 됩니다. 이미지 분할은 의료 영상, 자율주행차, 위성 영상화 분야에서 많이 응용이 되고 있습니다."
      ],
      "metadata": {
        "id": "FhtDpS4QdUrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 튜토리얼에 사용 될 데이터 세트는 Parkhi et al이 만든 [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)입니다. 데이터 세트는 영상, 해당 레이블과 픽셀 단위의 마스크로 구성됩니다. 마스크는 기본적으로 각 픽셀의 레이블입니다. 각 픽셀은 다음 세 가지 범주 중 하나가 주어집니다:"
      ],
      "metadata": {
        "id": "IKaCzrfJdXvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- class 1 : 애완동물이 속한 픽셀\n",
        "- class 2 : 애완동물과 인접한 픽셀\n",
        "- class 3 : 위에 속하지 않는 경우/주변 픽셀"
      ],
      "metadata": {
        "id": "XeLoHfqceK7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q git+https://github.com/tensorflow/examples.git"
      ],
      "metadata": {
        "id": "_dWCwMaKeREA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U tfds-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZmsbWC_gk0x",
        "outputId": "bd657ccf-39f5-4492-c95b-6f75c544695a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.1 MB 7.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Qqc6eS5phOc5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JdMyVuYXhUb2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oxford-IIIT Pets 데이터 세트를 다운로드 하기"
      ],
      "metadata": {
        "id": "UZ_mSyokht9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 세트는 이미 텐서플로 데이터 세트에 포함되어 있으며, 다운로드만 하면 됩니다. 분할 마스크는 버전3+에 포함되어 있습니다."
      ],
      "metadata": {
        "id": "CBN1nxTpiTN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tkxSPTRicwh",
        "outputId": "3ff20021-e18d-4ce4-ec2a-71ac6f31bf37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset 773.52 MiB (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0...\u001b[0m\n",
            "\u001b[1mDataset oxford_iiit_pet downloaded and prepared to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbAFYo30jjS7",
        "outputId": "f4eb2a19-e31e-47ca-a67f-09fd06f48bb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <PrefetchDataset shapes: {file_name: (), image: (None, None, 3), label: (), segmentation_mask: (None, None, 1), species: ()}, types: {file_name: tf.string, image: tf.uint8, label: tf.int64, segmentation_mask: tf.uint8, species: tf.int64}>,\n",
              " 'train': <PrefetchDataset shapes: {file_name: (), image: (None, None, 3), label: (), segmentation_mask: (None, None, 1), species: ()}, types: {file_name: tf.string, image: tf.uint8, label: tf.int64, segmentation_mask: tf.uint8, species: tf.int64}>}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhcBoj24jkWm",
        "outputId": "f87edcf0-e9a2-425e-e39d-0e8ed9069f01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='oxford_iiit_pet',\n",
              "    full_name='oxford_iiit_pet/3.2.0',\n",
              "    description=\"\"\"\n",
              "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
              "    images for each class. The images have large variations in scale, pose and\n",
              "    lighting. All images have an associated ground truth annotation of breed.\n",
              "    \"\"\",\n",
              "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
              "    data_path='/root/tensorflow_datasets/oxford_iiit_pet/3.2.0',\n",
              "    download_size=773.52 MiB,\n",
              "    dataset_size=774.69 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'file_name': Text(shape=(), dtype=tf.string),\n",
              "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=37),\n",
              "        'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),\n",
              "        'species': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
              "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
              "    },\n",
              "    citation=\"\"\"@InProceedings{parkhi12a,\n",
              "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
              "      title        = \"Cats and Dogs\",\n",
              "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
              "      year         = \"2012\",\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 코드는 이미지를 뒤집는 간단한 확장을 수행합니다. 또한, 영상이 [0,1]로 정규화됩니다. 마지막으로, 위에서 언급한 것처럼 분할 마스크의 픽셀에 {1, 2, 3}이라는 레이블이 붙습니다. 편의성을 위해 분할 마스크에서 1을 빼서 레이블이 {0, 1, 2}이 되도록 합시다."
      ],
      "metadata": {
        "id": "lQtzxuoBj3cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -=1\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "ydZdC-9ajv9n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128,128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128,128))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # 이미지와 마스크 정보(레이블)를 같이 플립 해줘야 한다.\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "mAGrKp4vkT-k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128,128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128,128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "2UQnlt6NmGBH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 세트에는 이미 필요한 몫의 시험과 훈련이 포함되어 있으므로 동일한 분할을 계속 사용합시다.\n",
        "\n",
        "상세내용은 위에 info를 프린트 하고있는 행을 다시 보자."
      ],
      "metadata": {
        "id": "fEgfb1ZtmKms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "metadata": {
        "id": "TuBRA88bnGqX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TRAIN_LENGTH)\n",
        "print(STEPS_PER_EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOWlouCNnsU0",
        "outputId": "9338dfc3-e8f0-4bfb-b6ad-a33c585ff9b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3680\n",
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SE9G_6f_oGpC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}